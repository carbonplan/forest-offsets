{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "import json\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "from dask.distributed import Client\n",
    "import fsspec\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.ops import cascaded_union\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "\n",
    "## And a bunch of carbonplan dependencies\n",
    "from carbonplan_data import cat as core_cat\n",
    "\n",
    "from carbonplan_forest_offsets.utils import aa_code_to_ss_code\n",
    "from carbonplan_forest_offsets.data import cat, get_retro_bucket\n",
    "from carbonplan_forest_offsets.analysis.assign_project_fldtypcd import load_classification_data\n",
    "from carbonplan_forest_offsets.load.geometry import (\n",
    "    get_overlapping_states,\n",
    "    load_supersections,\n",
    ")\n",
    "from carbonplan_forest_offsets.load.project_db import load_project_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aoi(ss_ids):\n",
    "    da = core_cat.nlcd.raster(region=\"conus\").to_dask()\n",
    "    crs = da.attrs[\"crs\"]\n",
    "\n",
    "    supersections = load_supersections().to_crs(crs)\n",
    "\n",
    "    subset_supersection = supersections[supersections[\"ss_id\"].isin(ss_ids)].copy()\n",
    "    subset_supersection.loc[:, \"dissolve_all\"] = 1\n",
    "\n",
    "    aoi = subset_supersection.dissolve(by=\"dissolve_all\").buffer(150_000).to_crs(\"epsg:4326\").item()\n",
    "    return aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def species_array_to_d(species_array):\n",
    "    return {str(species[\"code\"]): round(species[\"fraction\"], 4) for species in species_array}\n",
    "\n",
    "\n",
    "def load_data(ss_ids):\n",
    "    \"\"\"returns trained classifier and data vectorizer to apply to multiple opr_ids\"\"\"\n",
    "\n",
    "    if (len(ss_ids) == 1) & (ss_ids[0] > 200):\n",
    "        data = load_classification_data([\"ak\"])\n",
    "\n",
    "    else:\n",
    "        da = core_cat.nlcd.raster(region=\"conus\").to_dask()\n",
    "        crs = da.attrs[\"crs\"]\n",
    "\n",
    "        supersections = load_supersections().to_crs(crs)\n",
    "\n",
    "        subset_supersection = supersections[supersections[\"ss_id\"].isin(ss_ids)].copy()\n",
    "        subset_supersection.loc[:, \"dissolve_all\"] = 1\n",
    "\n",
    "        aoi = (\n",
    "            subset_supersection.dissolve(by=\"dissolve_all\")\n",
    "            .buffer(150_000)\n",
    "            .to_crs(\"epsg:4326\")\n",
    "            .item()\n",
    "        )\n",
    "\n",
    "        postal_codes = get_overlapping_states(aoi)\n",
    "        print(f\"preparing to load: {[x for x in postal_codes]}\")\n",
    "        data = load_classification_data(postal_codes, aoi=aoi)\n",
    "    return data\n",
    "\n",
    "\n",
    "def prepare_regional_classifier(data):\n",
    "    \"\"\"returns trained classifier and data vectorizer to apply to multiple opr_ids\"\"\"\n",
    "\n",
    "    base_clf = RadiusNeighborsClassifier(weights=\"distance\", algorithm=\"brute\", outlier_label=-999)\n",
    "    param_grid = [\n",
    "        {\"radius\": np.arange(0.15, 0.651, 0.025)}\n",
    "    ]  # initial testing never yielded a case where we went above 0.5\n",
    "\n",
    "    print(f\"doing GridSearch \")\n",
    "\n",
    "    clf = GridSearchCV(base_clf, param_grid, cv=5, refit=True, verbose=10)\n",
    "    start = time()\n",
    "    with joblib.parallel_backend(\"dask\"):\n",
    "        clf.fit(data[\"features\"], data[\"targets\"])\n",
    "    print(\"search took %.2f seconds\" % (time() - start))\n",
    "    return clf, data[\"dictvectorizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_db = cat.project_db_json.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cache = {}  # keep cache one step outside so dont overwrite it :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supersection_ids = list(set(chain(*[project[\"supersection_ids\"] for project in project_db])))\n",
    "\n",
    "classifications = defaultdict(dict)\n",
    "\n",
    "for ssid in supersection_ids:\n",
    "    print(ssid)\n",
    "\n",
    "    data = load_data([ssid])\n",
    "    data_encoder = data[\"dictvectorizer\"]\n",
    "\n",
    "    # train the classifier\n",
    "    clf, data_encoder = prepare_regional_classifier(data)\n",
    "    clf_cache[ssid] = clf, data_encoder\n",
    "\n",
    "    for project in project_db:\n",
    "        # excluded projects; see Extended Methods.\n",
    "        if project[\"opr_id\"] in [\"CAR1094\", \"CAR1032\", \"ACR360\", \"CAR1102\"]:\n",
    "            continue\n",
    "\n",
    "        if ssid not in project[\"supersection_ids\"]:\n",
    "            continue\n",
    "\n",
    "        for aa in project[\"assessment_areas\"]:\n",
    "\n",
    "            if (aa[\"code\"] == 999) or (\n",
    "                aa_code_to_ss_code().get(aa[\"code\"], False) == ssid and aa[\"species\"]\n",
    "            ):\n",
    "                species_arr = aa[\"species\"]\n",
    "                feat_dict = species_array_to_d(species_arr)\n",
    "                feats = data_encoder.transform(feat_dict)\n",
    "                classification = pd.Series(clf.predict_proba(feats).flatten(), index=clf.classes_)\n",
    "                classifications[project[\"opr_id\"]][str((ssid, aa[\"code\"]))] = (\n",
    "                    classification[classification > 0].sort_values().to_dict()\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store some outputs\n",
    "\n",
    "Store the 5-fold CV radius parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_radii = {k: v[0].best_params_[\"radius\"] for k, v in clf_cache.items()}\n",
    "\n",
    "fs_prefix, fs_kwargs = get_retro_bucket()\n",
    "fn = f\"{fs_prefix}/results/radius_neighbor_params.json\"\n",
    "with fsspec.open(fn, mode=\"w\", **fs_kwargs) as f:\n",
    "    json.dump(fit_radii, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_prefix, fs_kwargs = get_retro_bucket()\n",
    "fn = f\"{fs_prefix}/results/classifications.json\"\n",
    "with fsspec.open(fn, mode=\"w\", **fs_kwargs) as f:\n",
    "    json.dump(classifications, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
