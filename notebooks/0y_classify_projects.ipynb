{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "\n",
    "from dask.distributed import Client\n",
    "import fsspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.ops import cascaded_union\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "\n",
    "## And a bunch of carbonplan dependencies\n",
    "from carbonplan_data import cat as core_cat\n",
    "\n",
    "from carbonplan_retro.data import cat\n",
    "from carbonplan_retro.analysis.assign_project_fldtypcd import load_classification_data\n",
    "from carbonplan_retro.load.geometry import (\n",
    "    get_overlapping_states,\n",
    "    load_supersections,\n",
    ")\n",
    "from carbonplan_retro.load.project_db import load_project_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def species_array_to_d(species_array):\n",
    "    return {str(species[\"code\"]): round(species[\"fraction\"], 4) for species in species_array}\n",
    "\n",
    "\n",
    "def prepare_regional_classifier(ss_ids):\n",
    "    \"\"\"returns trained classifier and data vectorizer to apply to multiple opr_ids\"\"\"\n",
    "    da = core_cat.nlcd.raster(region=\"conus\").to_dask()\n",
    "    crs = da.attrs[\"crs\"]\n",
    "\n",
    "    supersections = load_supersections().to_crs(crs)\n",
    "\n",
    "    subset_supersection = supersections[supersections[\"ss_id\"].isin(ss_ids)].copy()\n",
    "    subset_supersection.loc[:, \"dissolve_all\"] = 1\n",
    "\n",
    "    aoi = subset_supersection.dissolve(by=\"dissolve_all\").buffer(150_000).to_crs(\"epsg:4326\").item()\n",
    "\n",
    "    postal_codes = get_overlapping_states(aoi)\n",
    "    print(f\"preparing to load: {[x for x in postal_codes]}\")\n",
    "\n",
    "    if (len(ss_ids) == 1) & (ss_ids[0] > 200):\n",
    "        data = load_classification_data(postal_codes)\n",
    "    else:\n",
    "        data = load_classification_data(postal_codes, bounds=aoi.bounds)\n",
    "\n",
    "    print(f\"fitting classifier \")\n",
    "    base_clf = RadiusNeighborsClassifier(weights=\"distance\", algorithm=\"brute\", outlier_label=-999)\n",
    "    param_grid = [\n",
    "        {\"radius\": np.arange(0.15, 0.651, 0.025)}\n",
    "    ]  # initial testing never yielded a case where we went above 0.5\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        base_clf, param_grid, n_jobs=int(os.cpu_count() / 2), cv=5, refit=True, verbose=10\n",
    "    )\n",
    "    clf.fit(data[\"features\"], data[\"targets\"])\n",
    "    return clf, data[\"dictvectorizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_db = load_project_db(\"/home/jovyan/lost+found/Forest-Offset-Projects-v0.3.json\")\n",
    "projects = project_db[~project_db[\"project\"][\"early_action\"].str.startswith(\"CAR\")]\n",
    "projects = projects[~project_db[\"project\"][\"species\"].isnull()]\n",
    "projects = projects[~projects[\"project\"][\"species\"].apply(lambda x: \"all\" in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cache = {}  # separate cell so you can re-run next cell if anything bonks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = defaultdict(dict)\n",
    "\n",
    "for opr_id, project in projects.iterrows():\n",
    "    if opr_id in [\"CAR1094\", \"CAR1032\"]:\n",
    "        print(f\"skipping {opr_id} -- discuss w group\")\n",
    "        continue\n",
    "\n",
    "    print(opr_id)\n",
    "    try:\n",
    "        clf, data_encoder = clf_cache[project[\"project\"][\"supersection_ids\"].astype(str).item()]\n",
    "    except:\n",
    "        clf, data_encoder = prepare_regional_classifier(\n",
    "            project[\"project\"][\"supersection_ids\"].item()\n",
    "        )\n",
    "        clf_cache[project[\"project\"][\"supersection_ids\"].astype(str).item()] = (clf, data_encoder)\n",
    "\n",
    "    for aa_id, species_arr in project_db[\"project\"][\"species\"][opr_id].items():\n",
    "\n",
    "        feat_dict = species_array_to_d(species_arr)\n",
    "        feats = data_encoder.transform(feat_dict)\n",
    "        classification = pd.Series(clf.predict_proba(feats).flatten(), index=clf.classes_)\n",
    "        classifications[opr_id][aa_id] = classification[classification > 0].sort_values().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store some outputs\n",
    "\n",
    "Store the 5-fold CV radius parameter as well as the classifications. Can't imagine we'd ever need to\n",
    "use the radii, but they're sort of expensive to compute so store for good measure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_radii = {k: v[0].best_params_[\"radius\"] for k, v in clf_cache.items()}\n",
    "\n",
    "with fsspec.open(\n",
    "    \"az://carbonplan-scratch/radius_neighbor_params.json\",\n",
    "    account_name=\"carbonplan\",\n",
    "    mode=\"w\",\n",
    "    account_key=os.environ[\"BLOB_ACCOUNT_KEY\"],\n",
    ") as f:\n",
    "    json.dump(fit_radii, f, indent=2)\n",
    "\n",
    "with fsspec.open(\n",
    "    \"az://carbonplan-scratch/project_radius_classification.json\",\n",
    "    account_name=\"carbonplan\",\n",
    "    mode=\"w\",\n",
    "    account_key=os.environ[\"BLOB_ACCOUNT_KEY\"],\n",
    ") as f:\n",
    "    json.dump(classifications, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
