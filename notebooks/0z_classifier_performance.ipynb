{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "import json\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "from dask.distributed import Client\n",
    "import fsspec\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.ops import cascaded_union\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "\n",
    "## And a bunch of carbonplan dependencies\n",
    "from carbonplan_data import cat as core_cat\n",
    "\n",
    "from carbonplan_retro.utils import aa_code_to_ss_code\n",
    "from carbonplan_retro.data import cat\n",
    "from carbonplan_retro.analysis.assign_project_fldtypcd import load_classification_data\n",
    "from carbonplan_retro.load.geometry import (\n",
    "    get_overlapping_states,\n",
    "    load_supersections,\n",
    ")\n",
    "from carbonplan_retro.load.project_db import load_project_db\n",
    "\n",
    "from carbonplan_retro.load.geometry import load_supersections\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aoi(ss_ids):\n",
    "    da = core_cat.nlcd.raster(region=\"conus\").to_dask()\n",
    "    crs = da.attrs[\"crs\"]\n",
    "\n",
    "    supersections = load_supersections().to_crs(crs)\n",
    "\n",
    "    subset_supersection = supersections[supersections[\"ss_id\"].isin(ss_ids)].copy()\n",
    "    subset_supersection.loc[:, \"dissolve_all\"] = 1\n",
    "\n",
    "    aoi = subset_supersection.dissolve(by=\"dissolve_all\").buffer(150_000).to_crs(\"epsg:4326\").item()\n",
    "    return aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def species_array_to_d(species_array):\n",
    "    return {str(species[\"code\"]): round(species[\"fraction\"], 4) for species in species_array}\n",
    "\n",
    "\n",
    "def load_data(ss_ids):\n",
    "    \"\"\"returns trained classifier and data vectorizer to apply to multiple opr_ids\"\"\"\n",
    "\n",
    "    if (len(ss_ids) == 1) & (ss_ids[0] > 200):\n",
    "        data = load_classification_data([\"ak\"])\n",
    "\n",
    "    else:\n",
    "        da = core_cat.nlcd.raster(region=\"conus\").to_dask()\n",
    "        crs = da.attrs[\"crs\"]\n",
    "\n",
    "        supersections = load_supersections().to_crs(crs)\n",
    "\n",
    "        subset_supersection = supersections[supersections[\"ss_id\"].isin(ss_ids)].copy()\n",
    "        subset_supersection.loc[:, \"dissolve_all\"] = 1\n",
    "\n",
    "        aoi = (\n",
    "            subset_supersection.dissolve(by=\"dissolve_all\")\n",
    "            .buffer(150_000)\n",
    "            .to_crs(\"epsg:4326\")\n",
    "            .item()\n",
    "        )\n",
    "\n",
    "        postal_codes = get_overlapping_states(aoi)\n",
    "        print(f\"preparing to load: {[x for x in postal_codes]}\")\n",
    "        data = load_classification_data(postal_codes, aoi=aoi)\n",
    "    return data\n",
    "\n",
    "\n",
    "def prepare_regional_classifier(data):\n",
    "    \"\"\"returns trained classifier and data vectorizer to apply to multiple opr_ids\"\"\"\n",
    "\n",
    "    base_clf = RadiusNeighborsClassifier(weights=\"distance\", algorithm=\"brute\", outlier_label=-999)\n",
    "    param_grid = [\n",
    "        {\"radius\": np.arange(0.15, 0.651, 0.025)}\n",
    "    ]  # initial testing never yielded a case where we went above 0.5\n",
    "\n",
    "    print(f\"doing GridSearch \")\n",
    "\n",
    "    clf = GridSearchCV(base_clf, param_grid, cv=5, refit=True, verbose=10)\n",
    "    start = time()\n",
    "    with joblib.parallel_backend(\"dask\"):\n",
    "        clf.fit(data[\"features\"], data[\"targets\"])\n",
    "    print(\"search took %.2f seconds\" % (time() - start))\n",
    "    return clf, data[\"dictvectorizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fsspec.open(\n",
    "    \"az://carbonplan-scratch/radius_neighbor_params.json\",\n",
    "    account_name=\"carbonplan\",\n",
    "    mode=\"r\",\n",
    "    account_key=os.environ[\"BLOB_ACCOUNT_KEY\"],\n",
    ") as f:\n",
    "    radii = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ss_id, radius in radii.items():\n",
    "    if ss_id not in store:\n",
    "        print(f\"scoring {ss_id}...\")\n",
    "\n",
    "        d = load_data([int(ss_id)])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            d[\"features\"], d[\"targets\"], stratify=d[\"targets\"], test_size=0.2\n",
    "        )\n",
    "        clf = RadiusNeighborsClassifier(\n",
    "            weights=\"distance\", algorithm=\"brute\", outlier_label=-999, radius=radius\n",
    "        )\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        preds = clf.predict(X_test)\n",
    "        scores = (\n",
    "            f1_score(y_test, preds, average=\"weighted\"),\n",
    "            f1_score(y_test, preds, average=\"micro\"),\n",
    "            f1_score(y_test, preds, average=\"macro\"),\n",
    "        )\n",
    "\n",
    "        store[ss_id] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(radii) == len(store):\n",
    "\n",
    "    ss_names = load_supersections(include_ak=False).set_index(\"ss_id\")[\"SSection\"].to_dict()\n",
    "\n",
    "    ss_names = {str(k): v for k, v in ss_names.items()}\n",
    "\n",
    "    renamed_store = {ss_names.get(k, k): v for k, v in store.items()}\n",
    "    del renamed_store[\"285\"]\n",
    "    del renamed_store[\"286\"]\n",
    "    renamed_store[\"Southeast and South Central Alaska\"] = renamed_store[\"287\"]\n",
    "    del renamed_store[\"287\"]\n",
    "\n",
    "    with fsspec.open(\n",
    "        \"az://carbonplan-retro/reclassification/classifier_fscores.json\",\n",
    "        account_name=\"carbonplan\",\n",
    "        mode=\"w\",\n",
    "        account_key=os.environ[\"BLOB_ACCOUNT_KEY\"],\n",
    "    ) as f:\n",
    "        json.dump(renamed_store, f, indent=2)\n",
    "else:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 14, \"svg.fonttype\": \"none\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = pd.DataFrame(renamed_store).T[0].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = tp.rename(\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tp.values\n",
    "cell_text = []\n",
    "for row in data:\n",
    "    cell_text.append([f\"{row:.2f}\"])\n",
    "\n",
    "# plt.table(rowLabels=tp.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3), tight_layout={\"pad\": 1})\n",
    "table = plt.table(\n",
    "    cellText=cell_text, rowLabels=tp.index.values, rowLoc=\"left\", loc=\"center\", edges=\"open\"\n",
    ")\n",
    "\n",
    "table.scale(1, 1.5)\n",
    "\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.box(on=None)\n",
    "plt.savefig(\"/home/jovyan/pub-figs/reclassification_accuracy.svg\", bbox_inches=\"tight\")  # dpi=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
