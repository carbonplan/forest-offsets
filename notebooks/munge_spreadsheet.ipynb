{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "import json\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from pandas import DataFrame, MultiIndex, to_datetime, to_numeric, read_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sheet(sheet, doc):\n",
    "    \"\"\"\n",
    "    helper function to open a specific google sheet\n",
    "    \"\"\"\n",
    "    scope = [\n",
    "        \"https://spreadsheets.google.com/feeds\",\n",
    "        \"https://www.googleapis.com/auth/drive\",\n",
    "    ]\n",
    "\n",
    "    credentials = ServiceAccountCredentials.from_json_keyfile_name(\n",
    "        \"carbonplan-03794eb9a308.json\", scope\n",
    "    )  # Your json file here\n",
    "\n",
    "    gc = gspread.authorize(credentials)\n",
    "    wks = gc.open(doc)\n",
    "    sheet = wks.worksheet(sheet)\n",
    "    return sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = get_sheet(\"Sheet2\", \"Forest-Offset-Projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df():\n",
    "    data = sheet.get_all_values()\n",
    "    data = np.asarray(data)\n",
    "    df = DataFrame(data[1:], columns=data[0])\n",
    "\n",
    "    levels = [\"level0\", \"level1\", \"level2\"]\n",
    "    left = df[levels].copy()\n",
    "    left[levels[:2]] = left[levels[:2]].mask(left == \"\", None).ffill()\n",
    "    index = MultiIndex.from_frame(left)\n",
    "\n",
    "    types = df[\"type\"]\n",
    "\n",
    "    df.index = index\n",
    "    df = df.drop(columns=levels + [\"type\"])\n",
    "    df = df.transpose()\n",
    "    df = df.iloc[1:]\n",
    "\n",
    "    types.index = index\n",
    "\n",
    "    return df, types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_loads(v):\n",
    "    try:\n",
    "        if \"SEE NOTE\" in v:\n",
    "            return None\n",
    "        return json.loads(v)\n",
    "    except:\n",
    "        print(v)\n",
    "        raise\n",
    "\n",
    "\n",
    "def cast_col(col, type_str):\n",
    "    if type_str == \"YYYY-MM-DD\":\n",
    "        return col  # to_datetime(col, errors='coerce')\n",
    "    elif type_str == \"str\" or type_str == \"str:previous_project_id\":\n",
    "        return col.astype(str)\n",
    "    elif type_str == \"bool\":\n",
    "        return col.astype(bool)\n",
    "    elif type_str == \"int\":\n",
    "        return to_numeric(col, errors=\"coerce\", downcast=\"integer\")\n",
    "    elif type_str == \"float\":\n",
    "        return to_numeric(col.str.replace(\",\", \"\"), errors=\"coerce\", downcast=\"float\")\n",
    "    elif type_str == \"[lon:float, lat:float]\" or type_str == \"[int]\":\n",
    "        return [json_loads(v) if v else [] for v in col]\n",
    "    elif type_str == \"[(is_intentional, size)]\":\n",
    "        return col  # TODO\n",
    "    else:\n",
    "        try:\n",
    "            return [json_loads(v) if v else \"\" for v in col]\n",
    "        except:\n",
    "            print(col)\n",
    "            raise\n",
    "\n",
    "\n",
    "df, types = get_df()\n",
    "\n",
    "for index, col in df.iteritems():\n",
    "    type_str = types[index]\n",
    "    df[index] = cast_col(col, type_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"retro.json\", orient=\"index\", date_format=\"iso\", date_unit=\"s\", indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip = lambda x: x.strip()\n",
    "\n",
    "\n",
    "def str_to_tuple(s):\n",
    "    return tuple(map(strip, s[1:-1].replace(\"'\", \"\").split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = read_json(\"retro.json\", orient=\"index\", convert_dates=True)\n",
    "df2.columns = MultiIndex.from_tuples(map(str_to_tuple, df2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.compare(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_project(name):\n",
    "    \"\"\"\n",
    "    return a template project\n",
    "    \"\"\"\n",
    "    obj = {\n",
    "        \"type\": \"Offset-Project\",\n",
    "        \"name\": name,\n",
    "        \"documents\": {},\n",
    "        \"project\": {},\n",
    "        \"live_carbon\": {},\n",
    "        \"baseline\": {},\n",
    "        \"rp\": [],\n",
    "    }\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = []\n",
    "for key, col in df.iterrows():\n",
    "    d = make_project(key)\n",
    "\n",
    "    # documents\n",
    "    keys = col[\"documents\"].index.get_level_values(0).unique()\n",
    "    d[\"documents\"].update({k: col[(\"documents\", k)].to_dict() for k in keys})\n",
    "\n",
    "    # project\n",
    "    temp = col[\"project\"]\n",
    "    temp.index = temp.index.droplevel(1)\n",
    "    d[\"project\"].update(temp.to_dict())\n",
    "\n",
    "    # live_carbon\n",
    "    d[\"live_carbon\"].update({\"components\": col[(\"live_carbon\", \"components\")].to_dict()})\n",
    "    d[\"live_carbon\"][\"notes\"] = col[(\"live_carbon\", \"notes\", \"\")]\n",
    "\n",
    "    # baseline\n",
    "    temp = col[\"baseline\"]\n",
    "    temp.index = temp.index.droplevel(1)\n",
    "    d[\"baseline\"].update(temp.to_dict())\n",
    "    d[\"baseline\"][\"components\"] = col[(\"baseline\", \"components\")].to_dict()\n",
    "    d[\"baseline\"][\"economics\"] = col[(\"baseline\", \"economics\")].to_dict()\n",
    "\n",
    "    # rp[0-?]\n",
    "    for i in range(7):\n",
    "        key = f\"rp[{i}]\"\n",
    "        if not col[(key, \"date_submitted\", \"\")]:\n",
    "            continue\n",
    "\n",
    "        temp = col[key]\n",
    "        temp.index = temp.index.droplevel(1)\n",
    "        rp = temp.to_dict()\n",
    "        rp[\"components\"] = col[(key, \"components\")].to_dict()\n",
    "        rp[\"attestation\"] = col[(key, \"attestation\")].to_dict()\n",
    "        d[\"rp\"].append(rp)\n",
    "    projects.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"retro_projects.json\", \"w\") as f:\n",
    "    f.write(json.dumps(projects, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
