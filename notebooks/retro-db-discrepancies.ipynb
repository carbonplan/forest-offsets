{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compares the final retro-db, containing all values extracted from Offset Project Data Reports (OPDRs), against the official ARB issuance table. \n",
    "\n",
    "This comparison is meant to accomplish two tasks. \n",
    "First, it should identify instances where OPDR data does not agree with the official ARB issuance outcome. \n",
    "Such discrepancies likely arise when the offset registries host out-of-date OPDRs (e.g., ARB issued ARBOCs on the basis of a separate/updated OPDR that we cannot access).\n",
    "Second, we want to demonstrate the ability to reconstruct ARBOC calculations from the raw \"IFM components\" that are reported in each OPDR. \n",
    "IFM projects are required to report numerous individual \"components\" when quantifying net changes in stored carbon.\n",
    "For IFM projects, the primary components include: \n",
    "\n",
    "- IFM-1: Standing live tree carbon (above \\& below ground)\n",
    "- IFM-3: Standing dead (\"all portions\")\n",
    "- IFM-7: Carbon contained in in-use forest products\n",
    "- IFM-8: Carbon contained in landfilled forest products\n",
    "\n",
    "IFM projects are also required to report \"secondary effects\", which accounts for several other \"secondary components.\"\n",
    "Each OPDR reports calculated secondary effects in section TK.\n",
    "\n",
    "Means we end up with three \"allocation\" values:\n",
    "- Issuance: the official, issued allocation of ARBOCs as recorded by ARB.\n",
    "- OPDR-Reported: the OPO/APD reported ARBC\n",
    "- OPDR-Calculated: issuance derived from IFM-1, IFM-3, IFM-7, IFM-8, and secondary effects (SE). \n",
    "\n",
    "In an ideal world, we would have agreement between all three values. \n",
    "This notebook allows us to explore cases where these values diverge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\nimport pathlib\\nimport sys\\n\\nimport numpy as np\\nfrom itertools import permutations\\nimport pandas as pd\\n\\nsys.path.append(\\\"/Users/darryl/proj/carbonplan/retro/\\\")\\n\\nfrom retrospective.load.issuance import issuance\\nfrom retrospective.load.retro import retro\\nfrom retrospective.analysis import allocation\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\nimport pathlib\\nimport sys\\n\\nimport numpy as np\\nfrom itertools import permutations\\nimport pandas as pd\\n\\nsys.path.append(\\\"/Users/darryl/proj/carbonplan/retro/\\\")\\n\\nfrom retrospective.load.issuance import issuance\\nfrom retrospective.load.retro import retro\\nfrom retrospective.analysis import allocation\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"/Users/darryl/proj/carbonplan/retro/\")\n",
    "\n",
    "from retrospective.load.issuance import issuance\n",
    "from retrospective.load.retro import retro\n",
    "from retrospective.analysis import allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load retro-db and issuance table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading load Forest-Offset-Projects-v0.3 from /Users/darryl/proj/carbonplan/retro/data\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"from retrospective.load.retro import retro\\n\\n\\nretro_db = retro(\\\"Forest-Offset-Projects-v0.3\\\", use_cache=True)\\n\\ngraduated_projects = [\\n    k\\n    for k, v in retro_db[\\\"project\\\"]\\n    .set_index(\\\"opr_id\\\")[\\\"early_action\\\"]\\n    .to_dict()\\n    .items()\\n    if v.startswith(\\\"CAR\\\")\\n]\";\n",
       "                var nbb_formatted_code = \"from retrospective.load.retro import retro\\n\\n\\nretro_db = retro(\\\"Forest-Offset-Projects-v0.3\\\", use_cache=True)\\n\\ngraduated_projects = [\\n    k\\n    for k, v in retro_db[\\\"project\\\"]\\n    .set_index(\\\"opr_id\\\")[\\\"early_action\\\"]\\n    .to_dict()\\n    .items()\\n    if v.startswith(\\\"CAR\\\")\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CAR1063',\n",
       " 'CAR1161',\n",
       " 'CAR1162',\n",
       " 'CAR1159',\n",
       " 'CAR1134',\n",
       " 'CAR1140',\n",
       " 'CAR1099',\n",
       " 'CAR1067',\n",
       " 'CAR1086',\n",
       " 'CAR1147',\n",
       " 'CAR1100',\n",
       " 'CAR1070',\n",
       " 'CAR1130',\n",
       " 'CAR1088',\n",
       " 'CAR1141',\n",
       " 'CAR1139',\n",
       " 'CAR1062',\n",
       " 'CAR1098',\n",
       " 'CAR1160']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"[\\n    k    for k, v in retro_db[\\\"project\\\"]\\n    .set_index(\\\"opr_id\\\")[\\\"early_action\\\"]\\n    .to_dict()\\n    .items()\\n    if v.startswith(\\\"CAR\\\")\\n    ]\";\n",
       "                var nbb_formatted_code = \"[\\n    k\\n    for k, v in retro_db[\\\"project\\\"]\\n    .set_index(\\\"opr_id\\\")[\\\"early_action\\\"]\\n    .to_dict()\\n    .items()\\n    if v.startswith(\\\"CAR\\\")\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retro_db = retro(\"Forest-Offset-Projects-v0.3\", use_cache=True)\n",
    "\n",
    "retro_db = retro_db[~retro_db[\"project\"][\"early_action\"].str.startswith(\"CAR\")]\n",
    "retro_db = retro_db[\n",
    "    retro_db[\"baseline\"][\"initial_carbon_stock\"]\n",
    "    > retro_db[\"baseline\"][\"common_practice\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issuance_table = issuance(\n",
    "    \"/Users/darryl/forest-retro/documents-of-interest/arb/issuance/arboc_issuance_2020-09-09.xlsx\"\n",
    ")\n",
    "issuance_table = issuance_table[\n",
    "    issuance_table[\"is_ea\"] == False\n",
    "]  # we didnt look at any of the EA proejcts in their EA form; exclude\n",
    "\n",
    "agg_by_rp = issuance_table.groupby([\"opr_id\", \"arb_rp_id\"])[\n",
    "    [\"allocation\", \"buffer_pool\"]\n",
    "].sum()  # One project has multiple issuance events in its first reporting period, aggregate them\n",
    "issuance_first_rp = agg_by_rp.xs(\"A\", level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opdr_calculated = allocation.calculate_allocation(retro_db, round_intermediates=False)\n",
    "compare_allocations = pd.concat(\n",
    "    [opdr_calculated, retro_db[\"rp_1\"][\"allocation\"].rename(\"opdr_reported\")], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    f\"There are {len(retro_db)} COP IFM projects where ICS > CP [we might relax this later]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_allocations = compare_allocations.join(\n",
    "    issuance_first_rp[\"allocation\"].rename(\"issuance\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_opdr = (\n",
    "    compare_allocations[\"opdr_reported\"] - compare_allocations[\"opdr_calculated\"]\n",
    ")\n",
    "delta_issuance = compare_allocations[\"opdr_reported\"] - compare_allocations[\"issuance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issuance and Reported do not agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issuance_reported_differ = delta_issuance[delta_issuance.abs() != 0]\n",
    "\n",
    "# hand classified\n",
    "reported_issuance_errors = {\n",
    "    \"unexplained\": [\"CAR1175\", \"CAR1257\", \"CAR1215\", \"CAR1264\", \"VCSOPR10\", \"CAR1213\"],\n",
    "    \"flagged_correctable\": [\"CAR1103\", \"CAR1208\"],\n",
    "    \"de_minimus\": [\"ACR284\", \"CAR1095\"],\n",
    "}\n",
    "\n",
    "assert sum([len(v) for v in reported_issuance_errors.values()]) == len(\n",
    "    issuance_reported_differ\n",
    ")  # 12 December 2020; if change you better understand why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When issuance and reported differ, its always the case that OPDR_calc and OPDR_reported are within 1 (rounding issue). \n",
    "This gives us confidence that the Issuance != Reported fall into three primary categories:\n",
    "\n",
    "1. Outdated OPDRs (5) [All at CAR]\n",
    "2. De minimus rounding considerations (2)\n",
    "3. Flagged Correctable (2)\n",
    "\n",
    "There is one possible exception: CAR1175. It seems that the OPDR is up-to-date but 30 too many ARBOCs have been issued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(delta_opdr[delta_issuance.abs() != 0] < 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshes = [1, 2, 10, 100]\n",
    "\n",
    "for thresh in threshes:\n",
    "    display(\n",
    "        f\"{len(compare_allocations[delta_opdr.abs() < thresh])} of the {len(retro_db)} projects are within {thresh} ARBOC(s)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I've gone through all cases where the difference is > 1 and tried to figure out what the heck is going on -- those learnings are reproduced below but also kept here as a \"comment\" dict so can output those comments on a per project basis to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = {\n",
    "    # Reported != Issuance\n",
    "    \"ACR248\": \"OPDRreported includes fractional ARBOC. We never round OPDRreported\",\n",
    "    \"CAR1095\": \"Allocation not reported in OPDR, only buffer pool contribution and our efforts to impute allocation yield a discrepancy\",\n",
    "    \"CAR1103\": \"Correctable Error note issued that matches Issuance\",\n",
    "    \"CAR1208\": \"Correctable Error note issued that matches Issuance\",\n",
    "    \"CAR1175\": \"Unexaplained. BH confirms 30 ARBOC difference\",\n",
    "    \"CAR1257\": \"Unexplained. Out of date OPDR?\",\n",
    "    \"CAR1215\": \"Unexplained. Out of date OPDR?\",\n",
    "    \"CAR1264\": \"Unexplained. OPDR reversal does not match Issuance-derived reversal. Seems likely an out of date OPDR.\",\n",
    "    \"VCSOPR10\": \"Unexplained.\",\n",
    "    \"CAR1213\": \"Unexplained. Initial OPDR has completion date that is more recent than Annual OPDR for RP1 and the two documents have different baselines. Seems Initial OPDR is out of date.\",\n",
    "    # Errors > 100\n",
    "    # Unexaplained\n",
    "    \"CAR1183\": \"OPDRreported is 1000 greater than OPDRcalculated. Unexplainable.\",\n",
    "    # CD rounding that is definitely overcreditting\n",
    "    \"ACR282\": \"OPDR reports CD of 0.3%. However, OPDRreported seems to assume CD == 0%. Results in over creditting.\",\n",
    "    # CD rounding that is perhaps overcreditting\n",
    "    \"ACR427\": \"OPDR reports CD of 2.445%, but OPDRreported seems to assume CD == 2.4%. Depending on how rounding is treated, could be overcreditting.\",\n",
    "    \"ACR360\": \"OPDR reports CD of 0.67% but OPDRreported seems to assume CD ~= 0.66531%. Likely not overcreditting but need clarification on rounding\",\n",
    "    # Harvest\n",
    "    \"ACR247\": \"Large harvest component -- still exploring. FC+TFG. BH agrees -- gets off by +12947. Has something to do with how they pro-rated haervest in baseline and potentially how they calculated secondary effects!\",\n",
    "    \"CAR1217\": \"Large harvest component -- still exploring. BH off by +1047 as well. \", \n",
    "    \"ACR276\": \"Large harvest component -- still exploring. BH off by +3298. Blue Source + TFG\",\n",
    "    # <= 100 & > 2; All explainable by CDreported != CDused\n",
    "    \"CAR1205\": \"TK -- recently entered, could have mistake\",\n",
    "    \"CAR1032\": \"Whole value so likely not rounding, BH also off by 2\",\n",
    "    \"CAR1094\": \"Could be caused by unrounded CD\",\n",
    "    \"ACR257\": \"Could be caused by unrounded CD\",\n",
    "    \"CAR1204\": \"Could be caused by unrounded CD\",\n",
    "    \"ACR256\": \"Could be caused by unrounded CD\",\n",
    "    \"ACR361\": \"Could be caused by unrounded CD [TK Double Check]\",\n",
    "    # Errors < 2 -- Explained by Leakage/CD rounding\n",
    "    \"ACR260\": \"Likely Rounding (CD and/or Leakage)\",\n",
    "    \"ACR288\": \"Likely Rounding (CD and/or Leakage)\",\n",
    "    \"CAR1314\": \"Likely Rounding (CD and/or Leakage)\",\n",
    "    \"ACR423\": \"Likely Rounding (CD and/or Leakage)\",\n",
    "    \"ACR182\": \"Likely Rounding (CD and/or Leakage)\",\n",
    "    \"CAR1104\": \"TK\",\n",
    "    # Errors < 2 -- Have CD == 0 but still could be leakage rounding error? Have confirmed data entered correctly\n",
    "    \"CAR1066\": \"CD == 0. Intermediate rounding?\",\n",
    "    \"ACR393\": \"CD == 0. Intermediate rounding?\",\n",
    "    \n",
    "    # old problems but now resolved\n",
    "    \"CAR1197\": \"could be something funny with harvest, IFM-7/IFM-8 but if just take all values at face, it works\",\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comparison = compare_allocations.join(\n",
    "    delta_issuance.rename(\"delta_reported_less_issuance\")\n",
    ").join(delta_opdr.rename(\"delta_reported_less_calculated\"))\n",
    "full_comparison[\"comment\"] = full_comparison.index.map(comments)\n",
    "\n",
    "full_comparison.to_csv(\"../data/odpr_issuance_math.csv\", float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ACR288: Using Initial OPDR reported value of 12.37% would yield 1.1 ARBOC difference\n",
    "- CAR1046: see allocation analysis -- think that documentation out of date. \n",
    "- ACR425: If use 10.6% 3.2 ARBOC difference\n",
    "- ACR458: If use 10.6% 78.478 ARBOC difference\n",
    "- CAR1130: Issuance table yields 19.21 -- feeds into previous discussion of rounding. RP1 OPDR and Initial use 19.2, but section 7.3 of Initial OPDR reports 19.24 percent. Issuance yields 19.21 -- what is going on here? \n",
    "\n",
    "## semi-unrelated\n",
    "- CAR1180: Undocumented change in risk reversal from Listing to RP1 because Initial is absent. What does FOP say about changes between listing and initial?\n",
    "- CAR1264: similar undocumented change -- looks like we only have an outdated Initial OPDR\n",
    "\n",
    "Questions of rounding become even more important when we get to confidence deductions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issuance_reversal = (\n",
    "    (issuance_first_rp[\"buffer_pool\"] / issuance_first_rp[\"allocation\"])\n",
    "    .round(4)\n",
    "    .rename(\"issuance_reversal\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reported_reversal = retro_db['project']['reversal_risk'].rename('reported_reversal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversal_risks = (\n",
    "    pd.concat([reported_reversal.round(4), issuance_reversal], axis=1)\n",
    "    .dropna()\n",
    "    .astype(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversal_risks.loc[\"CAR1205\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversal_risks[\n",
    "    reversal_risks[\"reported_reversal\"] != reversal_risks[\"issuance_reversal\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delta_allocation[delta_allocation.abs() >= 100].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reported != Issuance\n",
    "## Early Action Errors\n",
    "- CAR1062 -- First reporting period of this project was a reversal -- allocation listed as n/a in issuance table. \n",
    "- CAR1070 -- likely just not most up to date initial OPDR? Verification report has wrong #.\n",
    "- CAR1161 (no note but partner project has note, so likely just out of date)\n",
    "- CAR1162 (and has a note!) had a correctable error in 2020 -- which meant that it only got issued 777 credits. \n",
    "\n",
    "## De minimus\n",
    "- ACR284: we never round\n",
    "\n",
    "## Documentation Error\n",
    "\n",
    "- CAR1095 -- no allocation listed in document and when impute from rounded values cannot get to issuance table\n",
    "\n",
    "## Correctable Errors\n",
    "\n",
    "- CAR1103 (BS) had a correctable error -- meant it was issued 3136 fewer credits. Project note provided, but no other details. \n",
    "- CAR1208 - another correctable error example.\n",
    "\n",
    "## Unexplained\n",
    "- CAR1175 -- this might be a transpose error? not sure -- why did it have allocation issued over three dates? BH gets same thing -- 30 too many. \n",
    "- CAR1257 -- maybe CAR forgot to upload correctable error?\n",
    "- CAR1215 -- ?? \n",
    "- CAR1264 -- has to be out of date -- has incorrect reversal calculation too\n",
    "- VCSOPR10 -- numbers just disagree -- no documentation explaining. Both Initial and Annual report values as appear in retro_db\n",
    "- CAR1213 -- this is meaningful example. Initial OPDR is newer than RP1. Baseline in Initial is lower than Baseline in RP1 that seems to be outdated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reported != Calculated\n",
    "## Bigger Errors\n",
    "\n",
    "### Just off?\n",
    "- CAR1183: was originally off by 1000 but only error i could find just made things worse. Transpose? [TK from BH]\n",
    "\n",
    "### Fairly Sure Rounding Error on Confidence \n",
    "\n",
    "#### Over creditting \n",
    "- ACR282: The OPDR reported number and the final issuance for first reporting period assumes that confdience deduction is equal to zero. \n",
    "OPDR reports a 0.3\\% CD. \n",
    "Rounding, here, yields an over crediting of 9171 ARBOCs.\n",
    "See `Extras` -- if set confidence deduction to 0, off by < 1. \n",
    "- ACR427: OPDR reports CD of 2.445\\%. \n",
    "If you round CD to 2.4\\%, OPDRcalculated = OPDRreported = Issuance. \n",
    "If rounding is not allowed, yields overcrediting of 4096 ARBOCs. \n",
    "\n",
    "#### Likely report rounded confidence deduction but use more precise (lower) CD.\n",
    "- ACR360: Reports a confidence deduction of 6.7\\%.\n",
    "If we change CD to 6.6531\\%, less than one ARBOC error. \n",
    "Seems likely the correct number of ARBOCs issued if CD can be reported to arbitrary precision.\n",
    "\n",
    "\n",
    "### Big Harvest/TC (mainly...)\n",
    "- ACR247 -- turns on how interp secondary fx? If scale IFM7/IFM8 by 1.5, it mostly works... [FC with harvest]\n",
    "- CAR1217 reports positive Secondary Effects -- this will be cast to zero by calcs -- but more broadly, is this entry correct? [FC, with harvest]. BH gets the same answer. \n",
    "- CAR1197 Think they give themselves credit for negative leakage? [FC with harvest! Error == SE!]\n",
    "- ACR276 similarly has a SE == 0, but to get their # right, need to have IFM7+IFM8actual - IFM7+IFM8baseline > 0 cast to 0. Still wrong after lots of effort to work through. IFM-7 and IFM-8 are probably too low because later RP have same values, but are roughly half as long [first RP == 551 days.]. Need BH back-up on this one. Defiitely could be incorrect [Blue Source w heavy harvest -- IFM7/8 scaling solve anything?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Middling Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_allocation[\n",
    "    (delta_allocation.abs() < 100) & (delta_allocation.abs() >= 2)\n",
    "].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CAR1032: Cannot be explained by confdience deduction. BH is off by exactly two as well!\n",
    "\n",
    "\n",
    "\n",
    "## More Rounding\n",
    "\n",
    "\n",
    "- CAR1094: Double checked -- seems explainable due to rounding of confidence deduction.\n",
    "- ACR257: Double checked RP[0] -- seems explainable by small rounding of confidence \n",
    "\n",
    "## Over 10 ARBOCs\n",
    "They're all explainable making reasonable inferences about rounding of confidence deduction\n",
    "- CAR1204: An error of 0.016035 would get you wi 0.5 of an ARBOC -- [ROUNDED REPORTING >> USED RIGHT VALUE]\n",
    "- ACR256: Confidence deduction reported at 1.00% -- but yeah likely culprit [double check w BH]\n",
    "- ACR361: Similar situation. Confidence reported as 3.4 percent [But its BS project -- need to double check]\n",
    "- CAR1205: TK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_allocation[\n",
    "    (delta_allocation.abs() >= 1) & (delta_allocation.abs() < 2)\n",
    "].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not rounding\n",
    "do not have confidence deductions. Double checked both but cannot explain difference -- likely due to some sort of rounding of intermediary steps in ARBOC calculation? \n",
    "\n",
    "\n",
    "- CAR1066 \n",
    "- ACR393 \n",
    "\n",
    "## Likely Rounding\n",
    "Remaining errors are small. We double checked them all on 8 Dec 2020 -- last time plan to revisit\n",
    "- [x] ACR260\n",
    "- [x] ACR288\n",
    "- [x] CAR1314\n",
    "- [x] ACR423\n",
    "- [x] ACR182 [from worksheet can see exactly how rounding of confidence stat effects things]\n",
    "- [ ] CAR1104 -- if use workbook number and not description in text, error disappears. BH TK.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
